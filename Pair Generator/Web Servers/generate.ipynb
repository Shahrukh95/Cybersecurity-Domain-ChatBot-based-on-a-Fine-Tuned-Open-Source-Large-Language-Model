{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to convert date format to full long date\n",
    "def convert_to_full_long_date(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%d/%m/%Y')\n",
    "    return date_obj.strftime(\"%d %B %Y\")\n",
    "\n",
    "# Read JSON data from a file\n",
    "with open('cleaned_web_servers_cve_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Update the 'Published Date' in each record\n",
    "for record in data:\n",
    "    record['Published Date'] = convert_to_full_long_date(record['Published Date'])\n",
    "\n",
    "# Convert back to JSON\n",
    "updated_json = json.dumps(data, indent=4)\n",
    "# print(updated_json)\n",
    "\n",
    "# Optionally, write the updated data back to a file\n",
    "with open('cleaned_web_servers_cve_data_dated.json', 'w') as file:\n",
    "    file.write(updated_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the question-answer pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens used in GPT-4-Turbo Response: 1060\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1282\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1051\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1354\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1039\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1177\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1479\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1162\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1109\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 920\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 788\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1249\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 994\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 876\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 843\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 941\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1004\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 886\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1232\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1104\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 921\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1168\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1032\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1027\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 820\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1215\n",
      "Taking a break for 5 seconds\n",
      "Tokens used in GPT-4-Turbo Response: 1346\n",
      "Taking a break for 5 seconds\n"
     ]
    }
   ],
   "source": [
    "# DATA IS TRUNCATED FROM THE START FOR SECOND ITERATION\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def clean_description(item):\n",
    "    item[\"Description\"] = item[\"Description\"].replace('\\n', '').replace('\\r', '').strip()\n",
    "    return item\n",
    "\n",
    "def clean_response(response):\n",
    "    # Remove invalid control characters\n",
    "    return ''.join(ch for ch in response if ch.isprintable() or ch in '\\t\\n\\r')\n",
    "\n",
    "def get_questions_answers(item):\n",
    "    client = OpenAI(api_key=os.getenv(\"API_KEY\"))\n",
    "\n",
    "    prompt = f\"The following is the information of a CVE:\\n\\n{json.dumps(item, indent=2)}\\n\\nPlease generate question and answer pairs for this information. Supplement the provided information with your own knowledge. Add code examples for this vulnerability in the answers if possible. Please also discuss possible attack scenarios of this vulnerability. Don't mention about the cut-off date of your own training data in the questions and answers. Dont mention in the questions and answers that a content for this vulnerability was provided to you. Always mention the CVE id in your questions.\\n\\nThe response should be in JSON format. Each set of question-answer pairs should be an object inside an array, with key-value pairs called 'question' and 'answer'. The parent key should be called 'data'.\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[{'role': 'user', 'content': f\"{prompt}\"}],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        response = completion.choices[0].message.content.strip()\n",
    "        clean_resp = clean_response(response)\n",
    "        print(f\"Tokens used in GPT-4-Turbo Response: {completion.usage.total_tokens}\")\n",
    "        return clean_resp\n",
    "    except Exception as e:\n",
    "        print(f\"Error in GPT-4-Turbo API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def append_to_excel(qa_pairs, filename):\n",
    "    df = pd.DataFrame(qa_pairs, columns=['Question', 'Answer'])\n",
    "    if os.path.isfile(filename):\n",
    "        book = pd.read_excel(filename)\n",
    "        df = pd.concat([book, df], ignore_index=True)\n",
    "    df.to_excel(filename, index=False)\n",
    "\n",
    "def main(json_file_path, excel_file_path):\n",
    "    data = read_json_file(json_file_path)\n",
    "\n",
    "    for item in data:\n",
    "        cleaned_item = clean_description(item)\n",
    "        json_response = get_questions_answers(cleaned_item)\n",
    "        if json_response:\n",
    "            try:\n",
    "                response_data = json.loads(json_response)\n",
    "                qa_pairs = [(qa['question'], qa['answer']) for qa in response_data.get(\"data\", [])]\n",
    "                append_to_excel(qa_pairs, excel_file_path)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON parsing error: {e}\")\n",
    "                print(f\"Invalid JSON response: {json_response}\")\n",
    "        print(\"Taking a break for 5 seconds\")\n",
    "        time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = 'cleaned_web_servers_cve_data_dated.json'\n",
    "    excel_file_path = 'web-servers-pairs.xlsx'\n",
    "    main(json_file_path, excel_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pair-data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
